{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "# Практическое задание 2\n",
    "\n",
    "## Общая информация\n",
    "\n",
    "Дата выдачи: 11.10.2016\n",
    "\n",
    "Срок сдачи: 24.10.2016 23:59MSK\n",
    "\n",
    "### О задании\n",
    "На сайтах для поиска работы можно найти сотни тысяч объявлений, каждое из которых состоит из пространного описания вакансии и предлагаемой зарплаты. Есть ли связь между описанием и зарплатой? Существуют ли определенные слова, которые наиболее сильно характеризуют зарплату? Можно ли найти другие информативные факторы? Вам предстоит ответить на эти вопросы, проанализировав выборку объявлений о работе в Великобритании.\n",
    "\n",
    "Практическое задание 2 посвящено работе с текстовыми данными и категориальными признаками и задачам бинарной классификации. Вы научитесь:\n",
    " * работать с категориальными признаками;\n",
    " * строить вещественные представления текстовых данных;\n",
    " * обучать и строить прогнозы линейных классификаторов при помощи scikit-learn и Vowpal Wabbit;\n",
    " * тестировать модели и проводить оценку качества в задачах бинарной классификации.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов. Кроме того, некоторые из заданий являются опциональными (необязательными), однако за их выполнение можно получить дополнительные баллы, которые позднее будут учитываться при проставлении оценок автоматом по курсу.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце Вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл \\*.ipynb в соответствии со следующим форматом: *HW2_Username.ipynb*, где *Username* — Ваша фамилия и инициалы на латинице (например, *HW2_IvanovII.ipynb*). Далее отправьте этот файл на hse.cs.ml+<номер группы>@gmail.com (например, hse.cs.ml+141@gmail.com для студентов группы БПМИ-141)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "Как было упомянуто ранее, в рамках данного задания мы будем решать задачу бинарной классификации для предсказания уровня заработной платы по тексту объявления о вакансии на примере набора данных с соревнования [Adzuna - Job Salary Prediction](https://www.kaggle.com/c/job-salary-prediction). Для начала пройдите по [ссылке](https://www.kaggle.com/c/job-salary-prediction/data) и скачайте файл Train_rev1 (при необходимости, зарегистрируйтесь на Kaggle).\n",
    "\n",
    "Посмотрим на данные в файле и загрузим их в DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,Title,FullDescription,LocationRaw,LocationNormalized,ContractType,ContractTime,Company,Category,SalaryRaw,SalaryNormalized,SourceName\r",
      "\r\n",
      "12612628,Engineering Systems Analyst,\"Engineering Systems Analyst Dorking Surrey Salary ****K Our client is located in Dorking, Surrey and are looking for Engineering Systems Analyst our client provides specialist software development Keywords Mathematical Modelling, Risk Analysis, System Modelling, Optimisation, MISER, PIONEEER Engineering Systems Analyst Dorking Surrey Salary ****K\",\"Dorking, Surrey, Surrey\",Dorking,,permanent,Gregory Martin International,Engineering Jobs,20000 - 30000/annum 20-30K,25000,cv-library.co.uk\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# print first 2 rows from Train_rev1.csv\n",
    "!head -n 2 Train_rev1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244768, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  12612628                        Engineering Systems Analyst   \n",
       "1  12612830                            Stress Engineer Glasgow   \n",
       "2  12612844                   Modelling and simulation analyst   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "3     Surrey, South East, South East             Surrey          NaN   \n",
       "4     Surrey, South East, South East             Surrey          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized        SourceName  \n",
       "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
       "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
       "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
       "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
       "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Train_rev1.csv', sep=',')\n",
    "print df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В оригинальной постановке предлагается рассматривать признак SalaryNormalized как целевой и решать задачу регрессии, однако в рамках данного задания мы сведём её к задаче бинарной классификации, разделив объекты на 2 группы: объявления о вакансиях с низкой и высокой зарплатами соответственно.\n",
    "\n",
    "<img src = \"http://salt.uaa.alaska.edu/kath/kti/mean_median2.gif\">\n",
    "\n",
    "В качестве порога разбиения объектов на группы будем рассматривать медиану признака SalaryNormalized. Заметим, что таким образом мы автоматически получим задачу классификации со сбалансированными классами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9oAAAH3CAYAAABEuieGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkUEbAAAAemTQBgAAgB4ZtAEAAKBH/z8QjKh7yCDAMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f45a0567e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# salary histogramm\n",
    "median = np.median(df['SalaryNormalized'])\n",
    "\n",
    "figsize(16,8)\n",
    "plt.hist(df['SalaryNormalized'], bins=50)\n",
    "plt.axvline(median, c='r')\n",
    "plt.xlabel('salary', fontsize=20)\n",
    "plt.ylabel('count', fontsize=20)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществим последние шаги по подготовке датасета:\n",
    "- бинаризуем признак SalaryNomalized по описанному ранее порогу;\n",
    "- исключим из выборки признак SalaryRaw, чтобы устранить утечку целевой переменной в признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>0</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>0</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>0</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>0</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>0</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  12612628                        Engineering Systems Analyst   \n",
       "1  12612830                            Stress Engineer Glasgow   \n",
       "2  12612844                   Modelling and simulation analyst   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "3     Surrey, South East, South East             Surrey          NaN   \n",
       "4     Surrey, South East, South East             Surrey          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "   SalaryNormalized        SourceName  \n",
       "0                 0  cv-library.co.uk  \n",
       "1                 0  cv-library.co.uk  \n",
       "2                 0  cv-library.co.uk  \n",
       "3                 0  cv-library.co.uk  \n",
       "4                 0  cv-library.co.uk  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SalaryNormalized'] = (df['SalaryNormalized'] > median).astype(int)\n",
    "df.drop('SalaryRaw', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (0 баллов) Разбейте получившуюся выборку на обучающую и контрольную в соотношении 70/30 с использованием перемешивания объектов.\n",
    "\n",
    "При разбиении используйте значение параметра random_state=42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "df_train, df_test = train_test_split(df, test_size=.3, random_state=42)\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация\n",
    "\n",
    "Как правило, модели, используемые в машинном обучении, применяются в предположении, что матрица \"объект-признак\" является вещественнозначной. Поэтому при работе с категориальными признаками и текстами сперва их необходимо привести к вещественному виду.\n",
    "\n",
    "Заметим, что в нашей задаче есть признаки, являющиеся текстами произвольной природы (Title, FullDescription), и категориальные признаки, принимающие ограниченное число значений (ContractType, Category и др.).\n",
    "\n",
    "Самый простой и понятный способ преобразования текстовых данных — векторизация. В этом случае для каждого слова, встречающегося в некотором набре текстов мы создаём отдельный новый признак, который будет равен $1$, когда слово встречается в заданном объекте, и $0$ – в противном случае.\n",
    "\n",
    "#### 2. (0.5 балла) Создайте текстовое описание объектов обучающей и контрольной выборок, объединив значения всех признаков каждого объекта выборки через символы пробела. После этого получите признаковое описание объектов, осуществив векторизацию получившихся текстов при помощи [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), обучив его на обучающей выборке и применив на контрольной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['Title', 'FullDescription', 'LocationRaw', 'LocationNormalized', 'ContractTime', 'Company', 'Category', 'SourceName', 'ContractType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for  df in df_train, df_test:\n",
    "    df['Text'] = df[columns].apply(lambda row: ' '.join(x if type(x) != float or not np.isnan(x) else '' for x in row), axis=1)\n",
    "    #df.drop(columns, axis=1, inplace=True)\n",
    "\n",
    "del df # not to get confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vec = CountVectorizer(stop_words='english', dtype=np.int16) # in reality the biggest number is 212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = vec.fit_transform(df_train['Text'])\n",
    "X_test = vec.transform(df_test['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array(df_train['SalaryNormalized'], dtype=np.bool)\n",
    "y_test = np.array(df_test['SalaryNormalized'], dtype=np.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. (1.5 балла) Обучите следующие модели на обучающей выборке:\n",
    " - [логистическую регрессию](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) из модуля sklearn с параметрами по умолчанию;\n",
    " - логистическую регрессию при помощи Vowpal Wabbit с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "cls = LogisticRegression()\n",
    "\n",
    "cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volkswagen time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_vw_data(file_name, X, y=None):\n",
    "    with open(file_name, 'w') as f:\n",
    "        for row_idx in xrange(X.shape[0]):\n",
    "            row = X.getrow(row_idx)\n",
    "            row_nz = row.nonzero()[1]\n",
    "            s = '|txt ' + ' '.join(words[word_idx] + ':' + str(row[0, word_idx]) for word_idx in row_nz).encode(\"ascii\", \"ignore\")\n",
    "            if y is not None:\n",
    "                print >> f, y[row_idx] * 2 - 1, s\n",
    "            else:\n",
    "                print >> f, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'w') as f:\n",
    "    for row_idx in xrange(X_train.shape[0]):\n",
    "        row = X_train.getrow(row_idx)\n",
    "        row_nz = row.nonzero()[1]\n",
    "        s = u' '.join(words[word_idx] + ':' + str(row[0, word_idx]) for word_idx in row_nz).encode(\"ascii\", \"ignore\")\n",
    "        print >> f, y_train[row_idx] * 2 - 1, u'|txt', s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = train.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.693147 0.693147            1            1.0  -1.0000   0.5000      194\n",
      "0.646836 0.600524            2            2.0  -1.0000   0.4515       66\n",
      "0.558552 0.470269            4            4.0  -1.0000   0.3270      126\n",
      "0.846570 1.134587            8            8.0  -1.0000   0.3939       97\n",
      "0.757598 0.668626           16           16.0  -1.0000   0.5116      119\n",
      "0.751379 0.745160           32           32.0  -1.0000   0.6702      167\n",
      "0.699284 0.647190           64           64.0  -1.0000   0.2022      192\n",
      "0.677567 0.655849          128          128.0  -1.0000   0.3876      188\n",
      "0.638811 0.600055          256          256.0  -1.0000   0.2825       90\n",
      "0.600354 0.561896          512          512.0   1.0000   0.7387       66\n",
      "0.560988 0.521622         1024         1024.0   1.0000   0.3117       76\n",
      "0.524526 0.488064         2048         2048.0   1.0000   0.7749      131\n",
      "0.507697 0.490869         4096         4096.0   1.0000   0.7297       96\n",
      "0.474387 0.441078         8192         8192.0   1.0000   0.5088       54\n",
      "0.446690 0.418994        16384        16384.0   1.0000   0.7854      136\n",
      "0.420026 0.393361        32768        32768.0   1.0000   0.8171       93\n",
      "0.394061 0.368096        65536        65536.0  -1.0000   0.0918      234\n",
      "0.370851 0.347642       131072       131072.0  -1.0000   0.1187       92\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 171337\n",
      "passes used = 1\n",
      "weighted example sum = 171337.000000\n",
      "weighted label sum = -5161.000000\n",
      "average loss = 0.361445\n",
      "best constant = -0.060262\n",
      "best constant's loss = 0.692693\n",
      "total feature number = 19691610\n"
     ]
    }
   ],
   "source": [
    "!vw --data train.txt --loss_function logistic --link logistic -f model.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (0.5 балла) Вычислите значения ROC-AUC, [F-меры](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), а также постройте [матрицу ошибок](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) для каждой из построенных в п. 3 моделей на контрольной выборке. Сравните построенные модели по качеству их работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = cls.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.878975\n",
      "ROC-AUC: 0.945126\n",
      "F1 score: 0.874840\n",
      "Confusion matrix:\n",
      "[[33485  4455]\n",
      " [ 4432 31059]]\n"
     ]
    }
   ],
   "source": [
    "print 'accuracy: %f' % metrics.accuracy_score(y_test, y_predict > .5)\n",
    "print 'ROC-AUC: %f' % metrics.roc_auc_score(y_test, y_predict)\n",
    "print 'F1 score: %f' % metrics.f1_score(y_test, y_predict > .5)\n",
    "print 'Confusion matrix:'\n",
    "print metrics.confusion_matrix(y_test, y_predict > .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для vw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'store_vw_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-b46e2e852171>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstore_vw_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'rm test.txt.cache'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'store_vw_data' is not defined"
     ]
    }
   ],
   "source": [
    "store_vw_data('test.txt', X_test)\n",
    "!rm test.txt.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -t -c -i model.vw -p out test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict_vw = np.loadtxt('out')\n",
    "\n",
    "print 'accuracy: %f' % metrics.accuracy_score(y_test, y_predict_vw > .5)\n",
    "print 'ROC-AUC: %f' % metrics.roc_auc_score(y_test, y_predict_vw)\n",
    "print 'F1 score: %f' % metrics.f1_score(y_test, y_predict_vw > .5)\n",
    "print 'Confusion matrix:'\n",
    "print metrics.confusion_matrix(y_test, y_predict_vw > .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обе модели имеют (почти) одинаковое качество работы\n",
    "При этом различия в следующем:\n",
    "1. VW использует 1 проход\n",
    "2. VW не имеет регуляризации\n",
    "\n",
    "Но в целом ничего удивительного в том, что схожие модели дают схожие результаты нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. (1 балл) Отсортируйте веса признаков для модели логистической регрессии из scikit-learn, полученной в п. 2. Какие слова из встречающихся в выборке имеют наибольшее/наименьшее влияние на значение целевой переменной? Проинтерпретируйте полученный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168433"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.coef_.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most important words: theladders nhsd a24 targetjobs noreen hcpc prestigenursing exert apl redmond\n"
     ]
    }
   ],
   "source": [
    "important = range(cls.coef_.size)\n",
    "important.sort(key=lambda x: cls.coef_[0,x], reverse=True)\n",
    "print '10 best words to meet in the description:', ' '.join(words[x] for x in important[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интерпретируем: Ladders, Inc. is a United States-based company providing an online job search service. It launched listing only vetted job offers with annual salaries of $100,000 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median < 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 worst words to meet in the description: collates tssr omar 88 phocas juniorbroker nijobfinder bv studentship elance\n"
     ]
    }
   ],
   "source": [
    "print '10 worst words to meet in the description:', ' '.join(words[x] for x in important[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!grep -i collates Train_rev1.csv | head -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорее всего работа, которая требует внимания - что-то не требующее особого образования. (Output клетки очищен потому, что он длинный и неприятный"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. (0.5 доп. балла) Отсортируйте веса признаков для модели логистической регрессии, полученной в п. 2 при помощи Vowpal Wabbit. Какие слова из встречающихся в выборке имеют наибольшее/наименьшее влияние на значение целевой переменной? Проинтерпретирйте полученный результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vw-varinfo, конечно, учит модель заново, но по-другому придётся заниматься очень неприятным разбором текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!~/vowpal_wabbit/utl/vw-varinfo --loss_function logistic --link logistic -c train.txt > varinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureName                                                                                                                                                   \t   HashVal   MinVal   MaxVal    Weight   RelScore\r\n",
      "txt^theladders                                                                                                                                                \t    143200     0.00     1.00   +1.3495    100.00%\r\n",
      "txt^optometrist                                                                                                                                               \t     11461     0.00    11.00   +0.9387     69.56%\r\n",
      "txt^samplying                                                                                                                                                 \t     11461     0.00     1.00   +0.9387     69.56%\r\n",
      "txt^hcpc                                                                                                                                                      \t    178898     0.00     6.00   +0.8807     65.26%\r\n",
      "txt^london                                                                                                                                                    \t    185690     0.00    23.00   +0.7354     54.50%\r\n",
      "txt^dba                                                                                                                                                       \t    175348     0.00    19.00   +0.6738     49.93%\r\n",
      "txt^lawyer                                                                                                                                                    \t    102818     0.00    10.00   +0.6391     47.35%\r\n",
      "txt^manager                                                                                                                                                   \t      8394     0.00    34.00   +0.6323     46.85%\r\n",
      "txt^restorative                                                                                                                                               \t    112514     0.00     4.00   +0.5847     43.33%\r\n"
     ]
    }
   ],
   "source": [
    "!head varinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом тут всё то же самое, optometrist на втором месте скорее всего - эффект от overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\r\n"
     ]
    }
   ],
   "source": [
    "!grep optometrist Train_rev1.csv | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или нет?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7028264931259287"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_weight = cls.coef_[0, vec.transform(['optometrist']).nonzero()[1][0]]\n",
    "opt_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(cls.coef_ > opt_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну ладно, там он тоже на хорошем месте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt^jobcentre                                                                                                                                                 \t     49928     0.00     5.00   -0.7380    -54.69%\r\n",
      "txt^cpcs                                                                                                                                                      \t     37758     0.00     7.00   -0.7691    -56.99%\r\n",
      "txt^graduate                                                                                                                                                  \t    190324     0.00    34.00   -0.9852    -73.00%\r\n",
      "txt^kfrimley12month_job                                                                                                                                       \t    190324     0.00     1.00   -0.9852    -73.00%\r\n",
      "txt^usfos                                                                                                                                                     \t    190324     0.00     1.00   -0.9852    -73.00%\r\n",
      "txt^uties                                                                                                                                                     \t    190324     0.00     1.00   -0.9852    -73.00%\r\n",
      "txt^assistant                                                                                                                                                 \t    205079     0.00    23.00   -1.1707    -86.75%\r\n",
      "txt^highlighted                                                                                                                                               \t    205079     0.00     3.00   -1.1707    -86.75%\r\n",
      "txt^spurious                                                                                                                                                  \t    205079     0.00     1.00   -1.1707    -86.75%\r\n",
      "txt^partie                                                                                                                                                    \t     46445     0.00    23.00   -1.1822    -87.60%\r\n"
     ]
    }
   ],
   "source": [
    "!tail varinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь всё тоже ясно - ассистентам платят мало, временно занятым платят мало, вчерашним студентам платят мало"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "новости из гугла: A chef de partie, station chef, or line cook, is a chef in charge of a particular area of production in a restaurant. In large kitchens, each chef de partie might have several cooks or assistants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r\n"
     ]
    }
   ],
   "source": [
    "!grep -i kfrimley12month_job Train_rev1.csv | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот это overfitting чистой воды - у нас же нет регуляризации, 1 проход, конечно, отчасти спасает от подобных спецэффектов, но не до конца"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "Ещё один способ работы с текстовыми данными — [TF-IDF](https://en.wikipedia.org/wiki/Tf–idf) (**T**erm **F**requency–**I**nverse **D**ocument **F**requency). Рассмотрим коллекцию текстов $D$.  Для каждого уникального слова $t$ из документа $d \\in D$ вычислим следующие величины:\n",
    "\n",
    "1. Term Frequency – количество вхождений слова в отношении к общему числу слов в тексте:\n",
    "$$\\text{tf}(t, d) = \\frac{n_{td}}{\\sum_{t \\in d} n_{td}},$$\n",
    "где $n_{td}$ — количество вхождений слова $t$ в текст $d$.\n",
    "1. Inverse Document Frequency\n",
    "$$\\text{idf}(t, D) = \\log \\frac{\\left| D \\right|}{\\left| \\{d\\in D: t \\in d\\} \\right|},$$\n",
    "где $\\left| \\{d\\in D: t \\in d\\} \\right|$ – количество текстов в коллекции, содержащих слово $t$.\n",
    "\n",
    "Тогда для каждой пары (слово, текст) $(t, d)$ вычислим величину:\n",
    "$$\\text{tf-idf}(t,d, D) = \\text{tf}(t, d)\\cdot \\text{idf}(t, D).$$\n",
    "\n",
    "Отметим, что значение $\\text{tf}(t, d)$ корректируется для часто встречающихся общеупотребимых слов при помощи значения $\\text{idf}(t, D).$\n",
    "\n",
    "Признаковым описанием одного объекта $d \\in D$ будет вектор $\\bigg(\\text{tf-idf}(t,d, D)\\bigg)_{t\\in V}$, где $V$ – словарь всех слов, встречающихся в коллекции $D$.\n",
    "\n",
    "#### 7. (0.5 балла) Создайте текстовое описание объектов обучающей и контрольной выборок, объединив значения всех признаков каждого объекта выборки через символы пробела. После этого получите признаковое описание объектов, вычислив вектор tf-idf для каждого объекта помощи [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html), обучив его на обучающей выборке и применив на контрольной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(stop_words='english')\n",
    "X_train = vec.fit_transform(df_train['Text'])\n",
    "X_test = vec.transform(df_test['Text'])\n",
    "\n",
    "y_train = np.array(df_train['SalaryNormalized'], dtype=np.bool)\n",
    "y_test = np.array(df_test['SalaryNormalized'], dtype=np.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. (0 баллов) Обучите следующие модели на обучающей выборке:\n",
    "- [логистическую регрессию](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) из модуля sklearn с параметрами по умолчанию;\n",
    "- логистическую регрессию при помощи Vowpal Wabbit с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = LogisticRegression()\n",
    "\n",
    "cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_vw_data('train-tfidf.txt', X_train, y_train)\n",
    "store_vw_data('test-tfidf.txt', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = train-tfidf.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.693147 0.693147            1            1.0  -1.0000   0.5000      194\n",
      "0.614733 0.536320            2            2.0  -1.0000   0.4151       66\n",
      "0.525927 0.437121            4            4.0  -1.0000   0.3150      126\n",
      "0.699164 0.872401            8            8.0  -1.0000   0.4148       97\n",
      "0.671989 0.644813           16           16.0  -1.0000   0.5010      119\n",
      "0.698374 0.724760           32           32.0  -1.0000   0.6439      167\n",
      "0.672396 0.646418           64           64.0  -1.0000   0.2214      192\n",
      "0.655620 0.638844          128          128.0  -1.0000   0.4130      188\n",
      "0.625681 0.595742          256          256.0  -1.0000   0.3192       90\n",
      "0.588950 0.552219          512          512.0   1.0000   0.8512       66\n",
      "0.548803 0.508656         1024         1024.0   1.0000   0.3106       76\n",
      "0.507976 0.467149         2048         2048.0   1.0000   0.7079      131\n",
      "0.487931 0.467885         4096         4096.0   1.0000   0.8172       96\n",
      "0.454782 0.421633         8192         8192.0   1.0000   0.5775       54\n",
      "0.424374 0.393966        16384        16384.0   1.0000   0.8110      136\n",
      "0.395720 0.367066        32768        32768.0   1.0000   0.8930       93\n",
      "0.369676 0.343632        65536        65536.0  -1.0000   0.2530      234\n",
      "0.347051 0.324426       131072       131072.0  -1.0000   0.0878       92\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 171337\n",
      "passes used = 1\n",
      "weighted example sum = 171337.000000\n",
      "weighted label sum = -5161.000000\n",
      "average loss = 0.338531\n",
      "best constant = -0.060262\n",
      "best constant's loss = 0.692693\n",
      "total feature number = 19691610\n"
     ]
    }
   ],
   "source": [
    "!vw --data train-tfidf.txt --loss_function logistic --link logistic -f model.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. (0.5 балла) Вычислите значения ROC-AUC, [F-меры](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), а также постройте [матрицу ошибок](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) для каждой из построенных в п. 8 моделей на контрольной выборке. Сравните построенные модели по качеству их работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = cls.predict_proba(X_test)[:,1]\n",
    "\n",
    "print 'accuracy: %f' % metrics.accuracy_score(y_test, y_predict > .5)\n",
    "print 'ROC-AUC: %f' % metrics.roc_auc_score(y_test, y_predict)\n",
    "print 'F1 score: %f' % metrics.f1_score(y_test, y_predict > .5)\n",
    "print 'Confusion matrix:'\n",
    "print metrics.confusion_matrix(y_test, y_predict > .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для vw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = out\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using cache_file = test-tfidf.txt.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0  unknown   0.5227      163\n",
      "0.000000 0.000000            2            2.0  unknown   0.0988      194\n",
      "0.000000 0.000000            4            4.0  unknown   0.2879       30\n",
      "0.000000 0.000000            8            8.0  unknown   0.0389      104\n",
      "0.000000 0.000000           16           16.0  unknown   0.6878      194\n",
      "0.000000 0.000000           32           32.0  unknown   0.6592      123\n",
      "0.000000 0.000000           64           64.0  unknown   0.9837       90\n",
      "0.000000 0.000000          128          128.0  unknown   0.9363      118\n",
      "0.000000 0.000000          256          256.0  unknown   0.6528      192\n",
      "0.000000 0.000000          512          512.0  unknown   0.0125      117\n",
      "0.000000 0.000000         1024         1024.0  unknown   0.6507      115\n",
      "0.000000 0.000000         2048         2048.0  unknown   0.0387       90\n",
      "0.000000 0.000000         4096         4096.0  unknown   0.6512      109\n",
      "0.000000 0.000000         8192         8192.0  unknown   0.6089      142\n",
      "0.000000 0.000000        16384        16384.0  unknown   0.8912      104\n",
      "0.000000 0.000000        32768        32768.0  unknown   0.9512      136\n",
      "0.000000 0.000000        65536        65536.0  unknown   0.5782       93\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 73431\n",
      "passes used = 1\n",
      "weighted example sum = 73431.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.000000\n",
      "total feature number = 8434888\n"
     ]
    }
   ],
   "source": [
    "!vw -t -c -i model.vw -p out test-tfidf.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict_vw = np.loadtxt('out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.872438\n",
      "ROC-AUC: 0.944684\n",
      "F1 score: 0.868789\n",
      "Confusion matrix:\n",
      "[[33053  4887]\n",
      " [ 4480 31011]]\n"
     ]
    }
   ],
   "source": [
    "print 'accuracy: %f' % metrics.accuracy_score(y_test, y_predict_vw > .5)\n",
    "print 'ROC-AUC: %f' % metrics.roc_auc_score(y_test, y_predict_vw)\n",
    "print 'F1 score: %f' % metrics.f1_score(y_test, y_predict_vw > .5)\n",
    "print 'Confusion matrix:'\n",
    "print metrics.confusion_matrix(y_test, y_predict_vw > .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И снова две модели имеют очень близкие характеристики качества работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. (0.5 балла) Сравните значения метрик из п. 9 со значениями, полученными в п. 5, и сравните соответствующие модели по качеству из работы.\n",
    "\n",
    "**Ответ**: Ой, ну (почти) никакой разницы нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. (1 балл) Отсортируйте веса признаков для модели логистической регрессии из scikit-learn, полученной в п. 8. Какие слова из встречающихся в выборке имеют наибольшее/наименьшее влияние на значение целевой переменной? Проинтерпретирйте полученный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "important = range(cls.coef_.size)\n",
    "important.sort(reverse=True, key=lambda x: cls.coef_[0, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 best words: optometrist director manager senior head theladders hcpc london locum leadership\n"
     ]
    }
   ],
   "source": [
    "print '10 best words:', ' '.join(words[w] for w in important[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я даже не готов комментировать - большинство из этих слов мы уже так или иначе видели. Да, менеджерам на высоких позициях, людям с большим опытом работы платят больше. optometrist меня немного удивляет, но просто их довольно много в тестовых данных и модель очень уверена, что этим людям платят много"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 worst words: myukjobs nijobfinder aat library partie nvq junior jobcentre graduate assistant\n"
     ]
    }
   ],
   "source": [
    "print '10 worst words:', ' '.join(words[w] for w in important[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И снова ничего удивительного - работы не требующие опыта или образования оплачиваются плохо, указаны всякие места, в которых не бывают высокооплачиваемые вакансии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. (0.5 доп. балла) Отсортируйте веса признаков для модели логистической регрессии, полученной в п. 8 при помощи Vowpal Wabbit. Какие слова из встречающихся в выборке имеют наибольшее/наименьшее влияние на значение целевой переменной? Проинтерпретирйте полученный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!~/vowpal_wabbit/utl/vw-varinfo --loss_function logistic --link logistic -c train-tfidf.txt > varinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureName                                                                                                                                                   \t   HashVal   MinVal   MaxVal    Weight   RelScore\n",
      "txt^theladders                                                                                                                                                \t    143200     0.00     0.20  +15.4606    100.00%\n",
      "txt^navisionjobs                                                                                                                                              \t     18796     0.00     0.06   +9.0283     58.40%\n",
      "txt^technicalsalesmanagerpigmentsfillerstosurfacecoatings_job                                                                                                 \t    131696     0.00     0.05   +8.0391     52.00%\n",
      "txt^cvbar                                                                                                                                                     \t     92071     0.00     0.05   +7.8985     51.09%\n",
      "txt^ryanh                                                                                                                                                     \t    236479     0.00     0.16   +7.2931     47.17%\n",
      "txt^allegisgroup                                                                                                                                              \t     52981     0.00     0.11   +6.7512     43.67%\n",
      "txt^dsfrecruitmentrac                                                                                                                                         \t    161375     0.00     0.08   +6.6264     42.86%\n",
      "txt^b2cdevelopment                                                                                                                                            \t    110295     0.00     0.13   +6.5596     42.43%\n",
      "txt^simonbath                                                                                                                                                 \t    110295     0.00     0.13   +6.5596     42.43%\n"
     ]
    }
   ],
   "source": [
    "!head varinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "О. Похоже, tf-idf намного больше смотрит на источник вакансии, чем на какие-то слова в её описании\n",
    "Похоже, tf-idf просто уменьшает влияние часто встречающихся слов в текстах - у них очень маленький idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\r\n"
     ]
    }
   ],
   "source": [
    "!grep -i technicalsalesmanagerpigmentsfillerstosurfacecoatings Train_rev1.csv | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАУ. Это не вполне overfit. Что же это такое?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!grep -i technicalsalesmanagerpigmentsfillerstosurfacecoatings Train_rev1.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Очистил вывод, чтобы не загромождать ноутбук)\n",
    "А. Ну всё ясно. Просто это 13 одинаковых вакансий, возможно на разных сайтах. А слово уникально. Обидно. Будь это соревнование, возможно стоило бы почистить данные от такого"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Счётчики\n",
    "\n",
    "Ранее в рамках данного задания при построении моделей мы объединяли значения всех признаков в единую строку, что предполагает равноправность всех признаков. Однако заметим, что в этом случае мы допускаем потерю информации: слово \"Glasgow\" может по-разному влиять на зарплату, если оно находится в названии объявления и в геолокации. Чтобы устранить этот недостаток, при создании текстового описания объекта будем объединять только значения признаков Title и FullDescription, а остальные будем рассматривать как категориальные. При этом с полученным текстовым описанием объекта будем работать, как раньше (при помощи векторизации или tf-idf), а для кодирования категориальных признаков используем **счётчики**.\n",
    "\n",
    "Идея этого метода состоит в том, чтобы заменить значение категориального признака на вероятность того, что объект с данным значением признака относится к положительному классу. Опишем эту идею более формально. Пусть у нас есть выборка $X = \\{ (x_i, y_i) \\}_{i=1}^l,$ и $j$-ый признак принимает значения из множества $U_j = \\{ u_{jn}\\}_{n=1}^{N_j},$ где $N_j$ — количество различных значений $j$-ого признака. Пусть $x_{ij} = u_{jn},$ тогда заменим значения $j$-ого категориального признака объекта $x_i$ на следующую оценку: \n",
    "$$\\hat{P}(y_i=+1|x_{ij}=u_{jn}) = \\frac{\\sum_{m=1}^l \\left[ x_{mj} = u_{jn} \\right] \\left[ y_m = +1 \\right]}{\\sum_{m=1}^l \\left[ x_{mj} = u_{jn} \\right]}.$$\n",
    "\n",
    "Однако заметим, что при таком способе формирования счётчиков мы учитываем в формуле для объекта $x_i$ его метку $y_i$, тем самым вносим информацию об ответе в признаки. Чтобы устранить этот недостаток, при вычислении счётчика будем исключать из рассмотрения текущий объект, т.е. рассматривать следующую оценку:\n",
    "$$\\hat{P}(y_i=+1|X_{ij}=u_{jn}) = \\frac{\\sum_{m=1, \\\\ m \\ne i}^l \\left[ x_{mj} = u_{jn} \\right] \\left[ y_m = +1 \\right]}{\\sum_{m=1, \\\\ m \\ne i}^l \\left[ x_{mj} = u_{jn} \\right]},$$\n",
    "\n",
    "#### 13. (0.5 балла) Создайте текстовое описание объектов обучающей и контрольной выборок, объединив значения признаков Title и FullDescription каждого объекта выборки через символ пробела, после чего перейдите к признаковому описанию объектов, вычислив вектор tf-idf аналогично п. 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_value(x):\n",
    "    if type(x) is float and np.isnan(x):\n",
    "        return ' ' #probably I have to use something like 'nan' here\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for  df in df_train, df_test:\n",
    "    df['Text'] = df.apply(lambda row: get_value(row['Title']) + ' ' + \n",
    "                                   get_value(row['FullDescription']), axis=1)\n",
    "    #df.drop(columns, axis=1, inplace=True)\n",
    "\n",
    "del df # not to get confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vec.fit_transform(df_train['Text'])\n",
    "X_test_tfidf = vec.transform(df_test['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. (1 балл) Закодируйте категориальные признаки (все, кроме Title и FullDescription) при помощи [one-hot encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), после чего обучите логистическую регрессию (при помощи scikit-learn или Vowpal Wabbit) на обучающей выборке. Вычислите значения ROC-AUC, [F-меры](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), а также постройте [матрицу ошибок](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) для полученной модели на контрольной выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "cols = [x for x in columns if x not in ['Title', 'FullDescription']]\n",
    "vec = DictVectorizer(dtype=np.float32)\n",
    "X_train_one_hot = vec.fit_transform(df_train[cols].fillna('NaN').to_dict(orient='records'))\n",
    "X_test_one_hot = vec.transform(df_test[cols].fillna('NaN').to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = sparse.hstack((X_train_tfidf, X_train_one_hot))\n",
    "X_test = sparse.hstack((X_test_tfidf, X_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cls = LogisticRegression()\n",
    "cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.872547\n",
      "ROC-AUC: 0.945792\n",
      "F1 score: 0.868677\n",
      "Confusion matrix:\n",
      "[[33118  4822]\n",
      " [ 4537 30954]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = cls.predict_proba(X_test)[:,1]\n",
    "\n",
    "print 'accuracy: %f' % metrics.accuracy_score(y_test, y_predict > .5)\n",
    "print 'ROC-AUC: %f' % metrics.roc_auc_score(y_test, y_predict)\n",
    "print 'F1 score: %f' % metrics.f1_score(y_test, y_predict > .5)\n",
    "print 'Confusion matrix:'\n",
    "print metrics.confusion_matrix(y_test, y_predict > .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. (2 балла) Для выборки, полученной в п. 13, закодируйте категориальные признаки (все, кроме Title и FullDescription) при помощи счётчиков, после чего обучите логистическую регрессию (при помощи scikit-learn или Vowpal Wabbit) на обучающей выборке. Вычислите значения ROC-AUC, [F-меры](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), а также постройте [матрицу ошибок](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) для полученной модели на контрольной выборке. \n",
    "\n",
    "Уделите внимание оптимальности вычисления счётчиков!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter_total = {x: Counter() for x in cols}\n",
    "counter_hit = {x: Counter() for x in cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in  cols:\n",
    "    for idx in df_train.index:\n",
    "        val = df_train[col][idx]\n",
    "        counter_total[col][val] += 1\n",
    "        if df_train['SalaryNormalized'][idx] == 1:\n",
    "            counter_hit[col][val] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_reg = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_map = {x: cols.index(x) for x in cols}\n",
    "X_train_counter = np.zeros(df_train[cols].shape, dtype=np.float32)\n",
    "for col in  cols:\n",
    "    for idx_num, idx in enumerate(df_train.index):\n",
    "        val = df_train[col][idx]\n",
    "        total = counter_total[col][val] - 1\n",
    "        hit = counter_hit[col][val]\n",
    "        if df_train['SalaryNormalized'][idx] == 1:\n",
    "            hit -= 1\n",
    "        X_train_counter[idx_num,col_map[col]] += (hit + k_reg * .5) / (total + k_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_counter = np.zeros(df_test[cols].shape, dtype=np.float32)\n",
    "for col in  cols:\n",
    "    for idx_num, idx in enumerate(df_test.index):\n",
    "        val = df_test[col][idx]\n",
    "        total = counter_total[col][val]\n",
    "        hit = counter_hit[col][val]\n",
    "        X_test_counter[idx_num,col_map[col]] += (hit + k_reg * .5) / (total + k_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = sparse.hstack((X_train_tfidf, X_train_counter))\n",
    "X_test = sparse.hstack((X_test_tfidf, X_test_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = LogisticRegression()\n",
    "cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.870722\n",
      "ROC-AUC: 0.944242\n",
      "F1 score: 0.866815\n",
      "Confusion matrix:\n",
      "[[33046  4894]\n",
      " [ 4599 30892]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = cls.predict_proba(X_test)[:,1]\n",
    "\n",
    "print 'accuracy: %f' % metrics.accuracy_score(y_test, y_predict > .5)\n",
    "print 'ROC-AUC: %f' % metrics.roc_auc_score(y_test, y_predict)\n",
    "print 'F1 score: %f' % metrics.f1_score(y_test, y_predict > .5)\n",
    "print 'Confusion matrix:'\n",
    "print metrics.confusion_matrix(y_test, y_predict > .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. (0.5 балла) Сравните значения метрик из п. 15 со значениями, полученными в п. 14, и сделайте вывод о качестве классификации для каждого из методов кодирования категориальных признаков.\n",
    "\n",
    "**Ответ:** и всё ещё наплевать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров\n",
    "\n",
    "#### 17. (1.5 доп. балла) Разбейте обучающую выборку на обучающую и валидационную в отношении 80/20. Для выборки, полученной в п. 13, подберите оптимальное количество фолдов, используемое при кодировании категориальных признаков (всех, кроме Title и FullDescription), путём оптимизации значения accuracy на валидационной выборке. Используйте следующие модели, аналогично также подобрав оптимальные значения указанных гиперпараметров:\n",
    "- логистическую регрессию из модуля sklearn с подбором коэффициента регуляризации;\n",
    "- логистическую регрессию при помощи Vowpal Wabbit с подбором следующих гиперпараметров:\n",
    "    - коэффициент регуляризации (--l2);\n",
    "    - количество эпох (--passes);\n",
    "    - длина градиентного шага (-l);\n",
    "    - длина N-грамм (--ngram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#оптимальность 1-фолда очевидна\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.948493\n",
      "cv score: 0.879975\n"
     ]
    }
   ],
   "source": [
    "cls = LogisticRegression(C=30) # Мне лень дружить GridSearchCV с train_test_split\n",
    "cls.fit(X_train, y_train)\n",
    "print 'train score: %f' % cls.score(X_train, y_train)\n",
    "print 'cv score: %f' % cls.score(X_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171337, 165394)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_vw_new(file_name, X_tfidf, X_counter, y=None):\n",
    "    with open(file_name, 'w') as f:\n",
    "        for row_idx in xrange(X_tfidf.shape[0]):\n",
    "            row = X_tfidf.getrow(row_idx)\n",
    "            row_nz = row.nonzero()[1]\n",
    "            s_tfidf = '|txt ' + ' '.join(words[word_idx] + ':' + str(row[0, word_idx]) for word_idx in row_nz).encode(\"ascii\", \"ignore\")\n",
    "            s_counter = '|cnt' + ' '.join(cols[i] + ':' + str(X_counter[row_idx, i]) for i in xrange(len(cols)))\n",
    "            if y is not None:\n",
    "                print >> f, y[row_idx] * 2 - 1, s_tfidf, s_counter\n",
    "            else:\n",
    "                print >> f, s_tfidf, s_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store_vw_new('train-cnt.txt', X_train_tfidf, X_train_counter, np.array(df_train['SalaryNormalized'], dtype=np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_vw_new('test-cnt.txt', X_test_tfidf, X_test_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = train-cnt.txt.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.693147 0.693147            1            1.0  -1.0000   0.5000      195\n",
      "0.490798 0.288449            2            2.0  -1.0000   0.2506       66\n",
      "0.533497 0.576197            4            4.0  -1.0000   0.4237      127\n",
      "0.606081 0.678664            8            8.0   1.0000   0.4435      105\n",
      "0.656705 0.707330           16           16.0  -1.0000   0.4744      107\n",
      "0.681880 0.707054           32           32.0  -1.0000   0.4530      103\n",
      "0.668636 0.655393           64           64.0  -1.0000   0.5010      117\n",
      "0.669991 0.671346          128          128.0  -1.0000   0.4089      225\n",
      "0.657199 0.644407          256          256.0  -1.0000   0.5225      113\n",
      "0.639698 0.622197          512          512.0   1.0000   0.5576      114\n",
      "0.614711 0.589723         1024         1024.0  -1.0000   0.3852      137\n",
      "0.591183 0.567655         2048         2048.0  -1.0000   0.3315       71\n",
      "0.567116 0.543049         4096         4096.0  -1.0000   0.2484      109\n",
      "0.533261 0.499405         8192         8192.0  -1.0000   0.1118       78\n",
      "0.499883 0.466505        16384        16384.0  -1.0000   0.4057       89\n",
      "0.468351 0.436820        32768        32768.0  -1.0000   0.3325       77\n",
      "0.437755 0.407159        65536        65536.0   1.0000   0.8298       87\n",
      "0.410352 0.382949       131072       131072.0  -1.0000   0.1922      210\n",
      "0.384607 0.384607       262144       262144.0  -1.0000   0.0455      146 h\n",
      "0.362073 0.339538       524288       524288.0  -1.0000   0.0173       73 h\n",
      "0.342164 0.322256      1048576      1048576.0  -1.0000   0.0997      164 h\n",
      "0.325873 0.309581      2097152      2097152.0  -1.0000   0.1673      177 h\n",
      "0.313092 0.300312      4194304      4194304.0  -1.0000   0.1356       79 h\n",
      "0.304088 0.295084      8388608      8388608.0  -1.0000   0.1309      179 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 137070\n",
      "passes used = 77\n",
      "weighted example sum = 10554390.000000\n",
      "weighted label sum = -304766.000000\n",
      "average loss = 0.293790 h\n",
      "best constant = -0.057768\n",
      "best constant's loss = 0.692730\n",
      "total feature number = 1207078565\n"
     ]
    }
   ],
   "source": [
    "!vw --data train-cnt.txt --loss_function logistic --link logistic -f model.vw --holdout_period 5 --passes 100 -c -l 1e-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. (0.5 доп. балла) Обучите указанные выше модели на обучающей выборке для оптимальных значений гиперпараметров, найденных в п. 17, после чего для каждой из моделей вычислите значения ROC-AUC, F-меры, а также постройте матрицу ошибок на контрольной выборке. Как качество классификации при помощи полученных в данном разделе моделей соотносится с моделями, полученными в предыдущих разделах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.877667\n",
      "ROC-AUC: 0.946503\n",
      "F1 score: 0.873847\n",
      "Confusion matrix:\n",
      "[[33336  4604]\n",
      " [ 4379 31112]]\n"
     ]
    }
   ],
   "source": [
    "cls = LogisticRegression(C=30) # Мне лень дружить GridSearchCV с train_test_split\n",
    "cls.fit(X_train, y_train)\n",
    "y_predict = cls.predict_proba(X_test)[:,1]\n",
    "\n",
    "print 'accuracy: %f' % metrics.accuracy_score(y_test, y_predict > .5)\n",
    "print 'ROC-AUC: %f' % metrics.roc_auc_score(y_test, y_predict)\n",
    "print 'F1 score: %f' % metrics.f1_score(y_test, y_predict > .5)\n",
    "print 'Confusion matrix:'\n",
    "print metrics.confusion_matrix(y_test, y_predict > .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!vw -t -c -i model.vw -p out test-cnt.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.877763\n",
      "ROC-AUC: 0.948717\n",
      "F1 score: 0.873894\n",
      "Confusion matrix:\n",
      "[[33354  4586]\n",
      " [ 4390 31101]]\n"
     ]
    }
   ],
   "source": [
    "y_predict_vw = np.loadtxt('out')\n",
    "\n",
    "print 'accuracy: %f' % metrics.accuracy_score(y_test, y_predict_vw > .5)\n",
    "print 'ROC-AUC: %f' % metrics.roc_auc_score(y_test, y_predict_vw)\n",
    "print 'F1 score: %f' % metrics.f1_score(y_test, y_predict_vw > .5)\n",
    "print 'Confusion matrix:'\n",
    "print metrics.confusion_matrix(y_test, y_predict_vw > .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Комментарий про качество работы: ОНО НЕ РАСТЁТ ПАЧИМУ??? У меня есть объяснение почему регуляризация (почти) бесполезна: ну пусть мы выучили что слово technicalsalesmanagerpigmentsfillerstosurfacecoatings означает «зарплата низкая». Качество на тесте это не сломает: на тесте нету этого слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вы можете поделиться своими мыслями по поводу этого задания."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Чего-то как-то не растущая точность демотивирует"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь — вставить вашу вторую любимую смешную картинку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://psv4.vk.me/c812126/u107697916/docs/a55c4c7e4878/giphy.gif?extra=90UOYQTh-lr6uyj0Hk8kYA64SqGBIgXvyOVf1BHwTTy6858xcS9bFMW3FC1AUfLaiGBnP7MoEu0Ab5SHVJlcUKX8Ty6voHR8NrSIalTj5OQfasHLhGaryV4\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А здесь — посоветовать преподавателям хороший фильм или сериал."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Звиняйте, не люблю кино"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
